# Historias de usuario

---

## üìù Descripciones Detalladas para el Sprint 1

### Tareas Cr√≠ticas (P0)

| **ID** | **T√≠tulo de la Tarea/Historia de Usuario** | **Descripci√≥n Detallada y Criterios de Aceptaci√≥n (DoD)** |
| --- | --- | --- |
| **1** | **Implementaci√≥n de RBAC con ServiceAccounts, Roles y RoleBindings dedicados** (5 SP) | **Descripci√≥n:** Configurar RBAC en Kubernetes para aplicar el Principio de M√≠nimo Privilegio. Se deben crear *ServiceAccounts* dedicados para **TODOS los 10 microservicios** (`api-gateway`, `cloud-config`, `service-discovery`, `user-service`, `product-service`, `order-service`, `payment-service`, `shipping-service`, `favourite-service`, `proxy-client`), definiendo *Roles* y *RoleBindings* que les otorguen solo los permisos estrictamente necesarios (p.ej., `get`/`list` de *ConfigMaps* y *Secrets*). Los *Deployments* correspondientes deben ser actualizados para usar el nuevo *ServiceAccount*.<br><br>**DoD:** 1) Manifiestos YAML versionados por servicio (`ServiceAccount`, `Role`, `RoleBinding`) en `infra/k8s/*` para **los 10 microservicios**. 2) `deployment.spec.serviceAccountName` aplicado y verificado en **todos los Deployments** (10/10 servicios). 3) Pruebas con `kubectl auth can-i` dentro de un Pod usando el SA (permitido a sus recursos y denegado a externos) para **al menos 3 servicios diferentes**. 4) Pol√≠tica por defecto "deny" (sin permisos impl√≠citos). 5) Evidencia en `docs/SEGURIDAD.md` con comandos y capturas (antes/despu√©s) mostrando **todos los ServiceAccounts creados**. |
| **2** | **Implementaci√≥n de Backend Remoto para Estado de Terraform (S3/Azure Storage)** (3 SP) | **Descripci√≥n:** Configurar un *backend* remoto (p.ej., Azure Storage Blob o AWS S3) para almacenar el archivo `terraform.tfstate`. Debe incluir **bloqueo del estado** para prevenir conflictos y estar parametrizado por ambiente (`dev`, `stage`, `prod`).<br><br>**DoD:** 1) Bloque `backend` configurado (Azure Storage: container + account + key o S3+DynamoDB lock). 2) `terraform init -reconfigure` exitoso y `terraform plan`/`apply` leyendo/escribiendo en remoto. 3) Demostraci√≥n de bloqueo: segundo `apply` concurrente queda bloqueado. 4) Variables/Workspaces por ambiente documentados. 5) Diagrama simple del flujo de estado agregado a `docs/infra`. |
| **3** | **Implementaci√≥n de Patrones de Resiliencia: Retry, Bulkhead, Fallback, Timeout** (5 SP) | **Descripci√≥n:** Implementar **Resilience4j** en **TODOS los microservicios que hacen llamadas HTTP a otros servicios** (p.ej., `order-service` ‚Üí `payment-service`, `proxy-client` ‚Üí todos los servicios backend, `api-gateway` ‚Üí servicios downstream) con `Retry`, `Bulkhead`, `Timeout` y opcional `CircuitBreaker`. Exponer m√©tricas y validar comportamiento bajo fallas simuladas.<br><br>**DoD:** 1) Config en `application.yml` + anotaciones o beans Resilience4j en **todos los servicios que consumen otros servicios** (m√≠nimo 5 servicios: `api-gateway`, `proxy-client`, `order-service`, `payment-service`, y al menos 2 m√°s). 2) Prueba controlada de latencia/fallo (simulaci√≥n) con logs de intentos y activaci√≥n de fallback en **al menos 2 flujos diferentes**. 3) M√©tricas visibles: `resilience4j_retry_*`, `resilience4j_bulkhead_*`, `resilience4j_circuitbreaker_*` en Prometheus/Grafana para **todos los servicios configurados**. 4) Test automatizado que confirma el retry/fallback en **al menos 2 servicios**. 5) Documentaci√≥n de par√°metros elegidos y trade-offs en `ARCHITECTURE_PATTERNS.md` con lista de **todos los servicios** donde se implement√≥. |
| **4** | **Implementaci√≥n de TLS/HTTPS en el API Gateway (Certificados y Configuraci√≥n)** (5 SP) | **Descripci√≥n:** Configurar la terminaci√≥n TLS para el tr√°fico expuesto por el API Gateway (LoadBalancer/Ingress + cert-manager/LE). Forzar HTTPS y buenas pr√°cticas (HSTS, TLS 1.2+).<br><br>**DoD:** 1) Ingress/Service con TLS v√°lido y *secret* gestionado por cert-manager. 2) Redirecci√≥n 80‚Üí443 validada. 3) Prueba externa con `curl -I` y navegador (cert v√°lido). 4) Resultado SSL Labs ‚â• A (evidencia). 5) `SecurityHeaders` documentados (HSTS) y configuraci√≥n versionada. |

---

### Tareas de Alta Prioridad (P1)

| **ID** | **T√≠tulo de la Tarea/Historia de Usuario** | **Descripci√≥n Detallada y Criterios de Aceptaci√≥n (DoD)** |
| --- | --- | --- |
| **5** | **Implementaci√≥n de Pruebas Unitarias y de Integraci√≥n (m√≠nimo 70% cobertura)** (8 SP) | **Descripci√≥n:** Aumentar la cobertura de pruebas hasta **‚â•70%** (Jacoco) en **TODOS los 10 microservicios** y a√±adir pruebas de integraci√≥n reales con *Testcontainers* (DB o dependencia remota) en **todos los servicios que interact√∫an con bases de datos o otros servicios** (p.ej., `order-service` ‚Üî `payment-service`, `user-service` ‚Üî DB, `product-service` ‚Üî DB).<br><br>**DoD:** 1) Reporte Jacoco ‚â•70% integrado a Sonar para **todos los 10 microservicios** (evidencia en pipeline de cada servicio). 2) `mvn verify` ejecuta unit/integration tests en CI (fallo si <70%) para **todos los servicios**. 3) Testcontainers levantando dependencia real (PostgreSQL, MySQL, o servicio HTTP) en **todos los servicios que tienen dependencias externas** (m√≠nimo 5 servicios con DB y 2 con integraci√≥n HTTP). 4) Evidencia de m√©tricas de tiempo/√©xito en pipeline para **todos los servicios**. 5) Secci√≥n "Pruebas" actualizada en `docs` con resultados de **todos los microservicios** (tabla con cobertura por servicio). |
| **6** | **Configuraci√≥n de Namespaces `stage` y `prod` en Kubernetes** (3 SP) | **Descripci√≥n:** Terraform modular para crear `stage` y `prod`, replicando *ConfigMaps*/*Secrets* base y pol√≠ticas m√≠nimas (ResourceQuota, LimitRange, NetworkPolicy) por entorno.<br><br>**DoD:** 1) `terraform apply` crea `stage` y `prod` (`kubectl get ns`). 2) Manifiestos base listos y aplicados (config/secrets/quotas/policies). 3) Pipelines parametrizadas para apuntar a `stage`/`prod` (sin despliegue autom√°tico a prod). 4) Documentaci√≥n de diferencias por ambiente. |
| **7** | **Documentaci√≥n de Sprints y HUs en GitHub Projects con Criterios de Aceptaci√≥n** (2 SP) | **Descripci√≥n:** Formalizar backlog (P0, P1, P2) como Issues/Tarjetas en GitHub Projects con Prioridad, SP, Sprint, DoD y responsable. Vistas por Sprint/Estado/Prioridad.<br><br>**DoD:** 1) 100% de HUs registradas con campos completos. 2) Plantilla de Issue con secciones: Contexto, DoD, Riesgos, Dependencias. 3) Vistas guardadas y compartidas (Sprint 1 y 2). 4) Enlaces entre Issue ‚Üî PRs ‚Üî Commits. |
| **8** | **Definici√≥n y Configuraci√≥n de Estrategia de Branching (GitFlow)** (2 SP) | **Descripci√≥n:** Definir GitFlow simplificado y proteger `main`/`develop` con PRs obligatorios, checks de CI y approvals. Documentar comandos/tipos de ramas/tags.<br><br>**DoD:** 1) `BRANCHING_GUIDE.md` en `main` con ejemplos y convenciones (nombres, commits, tags). 2) Branch protection activada (PR + status checks + approvals + no force‚Äëpush + linear history/squash). 3) Validaci√≥n: intento de push directo bloqueado. |
| **9** | **Formalizaci√≥n del Uso de Gesti√≥n Segura de Secretos (Kubernetes Secrets)** (3 SP) | **Descripci√≥n:** Garantizar que **TODOS los secretos de TODOS los 10 microservicios** son gestionados a trav√©s de Kubernetes Secrets/SealedSecrets/ExternalSecrets; eliminar secretos hardcodeados en c√≥digo/manifiestos de **todos los servicios**; references via `valueFrom`/vol√∫menes en **todos los Deployments**.<br><br>**DoD:** 1) Scan de repos (grep/trufflehog) sin hallazgos de secretos en **todos los repositorios de microservicios** (10/10). 2) **Todos los 10 Deployments** consumen secretos desde K8s (no literales) - verificado con `kubectl describe deployment <service> -n <namespace>` para cada servicio. 3) Procedimiento de rotaci√≥n documentado aplicable a **todos los servicios**. 4) Evidencia con `kubectl describe` de `envFrom/valueFrom` o mounts para **todos los servicios** (capturas o script que valide los 10 servicios). |
| **10** | **Implementaci√≥n del Patr√≥n de Configuraci√≥n: Feature Toggle** (3 SP) | **Descripci√≥n:** Implementar *Feature Toggle* (Flipt/Config Server) en **al menos 3 microservicios diferentes** para activar/desactivar en caliente funcionalidades reales (p.ej., endpoint de promoci√≥n en `product-service`, feature de checkout r√°pido en `order-service`, modo mantenimiento en `api-gateway`) sin redeploy.<br><br>**DoD:** 1) Toggle remoto funcionando en **m√≠nimo 3 servicios** (cambio visible sin reinicio en cada uno). 2) Pruebas automatizadas de on/off para **todos los toggles implementados**. 3) M√©trica/log de auditor√≠a del estado del toggle en **todos los servicios con toggle**. 4) Gu√≠a de operaci√≥n para activaci√≥n segura y caducidad de toggles, listando **todos los servicios** donde se implement√≥. |
| **11** | **Documentar Prop√≥sito y Beneficios de todos los Patrones Implementados** (2 SP) | **Descripci√≥n:** `ARCHITECTURE_PATTERNS.md` listando ‚â•10 patrones (Gateway, Discovery, Config, Circuit Breaker, Retry, Bulkhead, Timeout, Feature Toggle, Observabilidad, Seguridad‚Ä¶), con herramienta, prop√≥sito, beneficios, trade-offs y enlaces a c√≥digo/config.<br><br>**DoD:** 1) Documento completo y versionado. 2) Cada patr√≥n con: problema, soluci√≥n, implementaci√≥n, m√©tricas/validaci√≥n, trade-offs. 3) V√≠nculos a dashboards/alertas si aplica. |

---

## üöÄ Descripciones Detalladas para el Sprint 2

### Tareas Prioritarias (P2)

| **ID** | **T√≠tulo de la Tarea/Historia de Usuario** | **Descripci√≥n Detallada y Criterios de Aceptaci√≥n (DoD)** |
| --- | --- | --- |
| **12** | **Infraestructura Multi-Cloud y Terragrunt** (8 SP) | **Descripci√≥n:** Extender la IaC a dos proveedores (Azure AKS + AWS EKS) usando m√≥dulos reutilizables/Terragrunt. Configurar backend remoto con bloqueo en ambas clouds y preparar diagramas actualizados.
<br><br>**DoD:** 1) C√≥digo Terraform/Terragrunt modular para AKS y EKS (repos separados o monorepo). 2) Backends remotos configurados (Azure Storage + DynamoDB/S3) con bloqueo demostrado. 3) `terraform plan/apply` exitoso en ambos entornos `dev`. 4) Diagrama de arquitectura multi-cloud en `docs/infra`. 5) Tabla comparativa de costos/performance inicial. |
| **13** | **CI/CD Avanzado con Promoci√≥n y Aprobaciones** (6 SP) | **Descripci√≥n:** Completar pipelines multi-ambiente (dev‚Üístage‚Üíprod) con gates/aprobaciones manuales, notificaciones (Slack/Teams), y rollback autom√°tico si falla etapa cr√≠tica.
<br><br>**DoD:** 1) GitHub Actions/GitHub Environments con approvals obligatorios para `prod`. 2) Pipeline ejecuta: build, pruebas (unit/integration), Trivy, Sonar, push, deploy dev, approval stage/prod. 3) Notificaciones configuradas (webhook) en fallos y despliegues. 4) Paso de rollback documentado/automatizado. |
| **14** | **GitOps con ArgoCD y Progressive Delivery** (6 SP) | **Descripci√≥n:** Instalar ArgoCD (AKS/EKS), sincronizar repos de manifiestos, habilitar Progressive Delivery (Argo Rollouts o Service Mesh) y notificaciones de sync.
<br><br>**DoD:** 1) ArgoCD desplegado y conectado al repo infra/manifests. 2) Sync autom√°tico a `dev` y manual a `stage/prod`. 3) Canary/Blue-Green demostrable (10%‚Üí100%). 4) Notificaciones de sync (Slack/email). 5) Rollback con ArgoCD verificado. |
| **15** | **Service Mesh con mTLS y Traffic Shifting** (7 SP) | **Descripci√≥n:** Implementar Istio/Linkerd en el cluster, habilitar mTLS entre **TODOS los 10 microservicios**, pol√≠ticas de retry/breaker en mesh para **todos los servicios** y visualizaci√≥n (Kiali/Jaeger). Integrar con Progressive Delivery.
<br><br>**DoD:** 1) Mesh instalado (profiles aplicados) y **todos los 10 microservicios** inyectados con sidecar. 2) mTLS activo (`STRICT`) y validado (`istioctl authn tls-check`) entre **todos los pares de servicios** (evidencia de comunicaci√≥n cifrada). 3) Reglas de retry/breaker en VirtualService/DestinationRule para **todos los servicios que consumen otros servicios** (m√≠nimo 5 servicios). 4) Traffic shifting usado en despliegue de **al menos 2 servicios**. 5) Dashboard Kiali/Jaeger mostrando trazas y rutas de **todos los 10 microservicios** en el mesh. |
| **16** | **Chaos Engineering con Chaos Mesh/Litmus** (5 SP) | **Descripci√≥n:** Instalar Chaos Mesh o Litmus, dise√±ar experimentos clave (pod kill, latency, loss) y documentar resultados + mejoras.
<br><br>**DoD:** 1) Experimentos definidos (YAML) y automatizados (GitHub Action/Workflow manual). 2) Ejecuci√≥n en `stage/dev` con reporte de impacto. 3) Ajustes derivados registrados (e.g., tuning resilience). 4) Informe en `docs/chaos` con evidencias. |
| **17** | **Observabilidad Extendida (Dashboards + Alertas + Tracing + Logs)** (6 SP) | **Descripci√≥n:** Completar stack de observabilidad con dashboards por servicio (SLIs/SLOs) para **TODOS los 10 microservicios**, alertas cr√≠ticas, EFK log central, tracing distribuido completo y m√©tricas de negocio.
<br><br>**DoD:** 1) Dashboards Grafana con P95, error rate, throughput y m√©tricas negocio (ventas/√≥rdenes) para **todos los 10 microservicios** (un dashboard por servicio o dashboard consolidado con paneles por servicio). 2) Alertas en Alertmanager (email/webhook) configuradas y probadas para **todos los servicios cr√≠ticos** (m√≠nimo 5 servicios: `api-gateway`, `order-service`, `payment-service`, `user-service`, `product-service`). 3) EFK/ELK ingesta logs JSON de **todos los servicios**, b√∫squeda por traceId funcionando. 4) Tracing en Jaeger/Zipkin con end-to-end mostrando **todos los servicios** en la traza completa. 5) Documentaci√≥n "Runbook observabilidad" con SLOs definidos para **todos los servicios**. |
| **18** | **Pruebas E2E, Rendimiento y Seguridad** (7 SP) | **Descripci√≥n:** Extender pruebas para cumplir r√∫brica: E2E completos, rendimiento con Locust, pruebas de seguridad (OWASP ZAP), reportes y automatizaci√≥n en pipeline.
<br><br>**DoD:** 1) Colecciones Postman/Flows E2E con datos din√°micos, ejecutadas en pipeline stage. 2) Locust pruebas (‚â•10min) con thresholds definidos; reportes en docs. 3) OWASP ZAP baseline activo (no bloquea pero reporta). 4) Resultados agregados a `docs/pruebas` con hallazgos/acciones. 5) Pipeline falla si ZAP detecta severidad alta sin excepci√≥n documentada. |
| **19** | **Release Management, Change Management y Semantic Release** (5 SP) | **Descripci√≥n:** Formalizar proceso de releases con semantic-release, etiquetas, release notes autom√°ticas, approvals, y plan de rollback/documento de cambios.
<br><br>**DoD:** 1) `semantic-release` funcionando en main con versi√≥n/tag + release notes. 2) Issues/PRs etiquetados autom√°ticamente (`released`). 3) Proceso de change management documentado (RFC luz/plantilla + approvals por entorno). 4) Plan de rollback por servicio (script/manual) probado. |
| **20** | **FinOps y Optimizaci√≥n de Costos Multi-Cloud** (4 SP) | **Descripci√≥n:** Implementar observabilidad de costos (Azure Cost Mgmt, AWS Cost Explorer), etiquetado, pol√≠ticas de ahorro (stop nocturno, autoscaling), dashboards de costos y reporte final.
<br><br>**DoD:** 1) Todos los recursos etiquetados (`env`, `service`, `owner`). 2) Dashboard de costos mensual por cloud/servicio. 3) Scripts/policies de ahorro (auto-stop, schedule). 4) Reporte en `docs/finops` con recomendaciones y estimaciones. |
| **21** | **Autoscaling avanzado con KEDA** (4 SP) | **Descripci√≥n:** Instalar KEDA y configurar ‚â•2 triggers diferentes (p.ej., Azure Queue, HTTP, CPU) para escalar **al menos 3 microservicios diferentes** seg√∫n eventos. Documentar pruebas y resultados.
<br><br>**DoD:** 1) KEDA en cluster (manifiestos y Helm chart versionado). 2) ScaledObject/ScaledJob con triggers funcionando para **m√≠nimo 3 servicios** (cada uno con trigger diferente: HTTP, CPU, Queue, etc.) - demostraci√≥n visual. 3) M√©tricas de escalado registradas para **todos los servicios con KEDA**. 4) Doc de pruebas (capturas, comandos) en `docs/autoscaling` listando **todos los servicios** configurados con KEDA. |
| **22** | **Documentaci√≥n Final, Presentaci√≥n y Demo** (4 SP) | **Descripci√≥n:** Consolidar documentaci√≥n final (arquitectura, IaC, patrones, pruebas, observabilidad, costos), preparar video demo (20-30 min) y presentaci√≥n.
<br><br>**DoD:** 1) Repo `docs/` completo (infra, operaci√≥n, patrones, pruebas, costos, chaos, runbooks). 2) Video demo mostrando arquitectura, CI/CD, app en multi-cloud, dashboards, pruebas. 3) Presentaci√≥n (deck) lista. 4) Checklist final de entregables firmado. |
